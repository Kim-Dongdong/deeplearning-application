{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a061def-55d5-4493-9704-69630f2482df",
   "metadata": {},
   "source": [
    "# 앙상블 학습\n",
    "- 정형 데이터를 다루는 데 가장 뛰어난 성과를 내는 알고리즘\n",
    "\n",
    "## 랜덤 포레스트\n",
    "- 앙상블 학습의 대표적인 모델\n",
    "- 여러 개의 결정트리(Decision Tree)를 조합하여 예측 성능을 높이는 앙상블(Ensemble) 학습 기법이다.\n",
    "- 원본 데이터에서 중복을 허용하면서 랜덤 샘플링을 하는 부트스트랩 샘플링을 진행한다.\n",
    "- RandomForestClassifier는 기본적으로 전체 특성 개수의 제곱근만큼의 특성을 선택한다. 즉 4개의 특성이 있다면 노드마다 2개를 랜덤하게 선택해 사용\n",
    "  - RandomForestRegressor는 전체 특성 사용\n",
    "- 분류일때는 각 트리의 클래스별 확률을 평균하여 가장 높은 확률을 가진 클래스를 예측한다.\n",
    "  - 회귀일 땐 단순히 각 트리의 예측을 평균한다.\n",
    "- 랜덤 포레스트는 랜덤하게 선택한 샘플과 특성을 사용하므로 과대적합을 막아주고, 검증과 테스트 세트에서 안정적인 성능을 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1d51b3a6-4236-422c-8607-6b9c1f8f56f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "wine = pd.read_csv(\"https://bit.ly/wine_csv_data\")\n",
    "data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n",
    "target = wine[['class']].to_numpy()\n",
    "train_input, test_input, train_target, test_target = train_test_split(\n",
    "    data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "54892dc1-128e-40b6-980f-90066cb9ccfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997844759088341 0.8914208392565683\n"
     ]
    }
   ],
   "source": [
    "# 교차 검증 수행. 여기선 cross_validate()함수 사용\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
    "# return_train_score=True로 지정하면 검증 점수뿐만 아니라 훈련세트에 대한 점수도 같이 반환한다.\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e16ae5b-b893-42e2-aa22-4ddf93e6d6c7",
   "metadata": {},
   "source": [
    "- 랜덤 포레스트는 결정 트리의 앙상블이므로 DecisionTreeClassifier가 제공하는 중요한 매개 변수를 모두 제공한다.\n",
    "- 결정 트리의 큰 장점 중 하나인 특성 중요도를 계산한다.\n",
    "  - 특성 중요도: 각 결정 트리의 특성 중요도를 취합한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4757ee9d-61ec-49eb-9933-a55a51cbb89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23155241 0.49706658 0.27138101]\n"
     ]
    }
   ],
   "source": [
    "# 특성 중요도 출력\n",
    "rf.fit(train_input, train_target)\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f280ad5-680a-49bb-bf43-7157aed5b7ba",
   "metadata": {},
   "source": [
    "- 앞의 결정트리와 다른 결과가 나왔는데, 이는 랜덤포레스트가 특성의 일부를 랜덤하게 선택해 결정 트리를 훈련하기 때문이다.\n",
    "- 이는 과대적합을 줄이고 일반화 성능을 높이는데 도움이 된다.\n",
    "\n",
    "### 자체 검증\n",
    "- 랜덤 포레스트는 OOB(남는 샘플 데이터)를 통해 부트스트랩 샘플로 훈련한 결정 트리를 평가할 수 있다.\n",
    "  - RandomForestClassifier의 oob_score=True로 지정해줘야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "49254269-ab26-41b3-918a-46f5646c7b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8981937602627258\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n",
    "rf.fit(train_input, train_target)\n",
    "print(rf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d66fae-01ec-455b-8d71-7e394dad4402",
   "metadata": {},
   "source": [
    "## 엑스트라 트리\n",
    "- 랜덤 포레스트와 다르게 부트스트랩 샘플을 사용하지 않는다. 즉 전체 훈련 세트를 사용한다.\n",
    "- 대신 노드를 분할할 때 가장 좋은 분할을 찾는것이 아닌 무작위 분할을 한다.\n",
    "- 많은 트리를 학습하므로 과대적합을 방지하고 검증 세트의 점수를 높일 수 있다.\n",
    "- 보통 엑스트라 트리가 랜덤 포레스트보다 무작위성이 커 더 많은 결정트리를 훈련해야한다.\n",
    "- 랜덤하게 노드를 분할하기 때문에 빠른 계산 속도가 장점이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0a5a1904-c29a-4b92-a59c-6eea2b894b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997844759088341 0.8903937240035804\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n",
    "scores = cross_validate(et, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b316e737-59e3-4dd0-8d06-4a2d73e6b55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20702369 0.51313261 0.2798437 ]\n"
     ]
    }
   ],
   "source": [
    "# 특성 중요도 파악\n",
    "et.fit(train_input, train_target)\n",
    "print(et.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee57a10-f1b7-4221-9828-4ca7d80d4dc0",
   "metadata": {},
   "source": [
    "## 그레디언트 부스팅\n",
    "- 깊이가 얕은 결정 트리를 사용해 이전 트리의 오차를 보완하는 방식\n",
    "- GradientBoostingClassifier는 기본적으로 깊이가 3인 결정 트리 100개를 사용한다.\n",
    "- 과대적합에 강하고 일반적으로 높은 일반화 성능을 기대할 수 있다.\n",
    "- 경사 하강법을 사용해 트리 앙상블에 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "24be9260-776d-4476-8a6b-3c1c3a5d6cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8894704231708938 0.8715107671247301\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8c25f9c7-fe2a-4bff-9fdb-0a32f65aed47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9512006117505237 0.879719686200179\n"
     ]
    }
   ],
   "source": [
    "# 결정 트리의 개수를 늘려도 과대적합에 매우 강하다.\n",
    "# 학습률을 증가시키고 트리의 개수를 늘려보자(n_estimators=500, learning_rate=0.2)\n",
    "gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, random_state=42)\n",
    "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d2526f5d-b17c-4c93-b285-ea5a844de882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1479308  0.68876707 0.16330213]\n"
     ]
    }
   ],
   "source": [
    "gb.fit(train_input, train_target)\n",
    "print(gb.feature_importances_)\n",
    "\n",
    "# 마찬가지로 당도에 좀 더 집중하는 모습을 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ccd38e-fc69-4dac-bb7b-bb11534f943a",
   "metadata": {},
   "source": [
    "## 히스토그램 기반 그레이디언트 부스팅\n",
    "- 정형 데이터를 다루는 머신러닝 알고리즘 중 가장 많이 쓰인다.\n",
    "- 입력 특성을 256개의 구간으로 나눔 -> 노드 분할 시 최적의 분할을 매우 빠르게 찾음\n",
    "- 256개 중 하나를 떼어 놓고 결측치값을 위해 사용함 -> 전처리 과정 축소\n",
    "- HistGradientBoostingClassifier 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1d483e72-e5a8-43ce-a3bf-c162aac45dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9380129799494501 0.8805410414363187\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(random_state=42)\n",
    "scores = cross_validate(hgb, train_input, train_target, return_train_score=True)\n",
    "\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8654a9a-36d4-4f50-bada-0256c272207e",
   "metadata": {},
   "source": [
    "- 특성 중요도를 계산하기 위해 permutation_importance() 함수 사용\n",
    "- n_repeats 매개변수는 랜덤하게 섞을 횟수 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "26b21f0f-7cf7-44ad-8cea-3b3edef2d4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09144089 0.23493432 0.08760263]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "hgb.fit(train_input, train_target)\n",
    "result = permutation_importance(hgb, train_input, train_target, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "print(result.importances_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fae997-8cd5-47ed-9f80-61a7e55f93da",
   "metadata": {},
   "source": [
    "- 조금 더 당도에 집중하고있음을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "660e880f-be69-4c91-8c9f-99486404a07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04141538 0.19827692 0.03870769]\n"
     ]
    }
   ],
   "source": [
    "# 테스트 세트에서에도 특성 중요도 파악\n",
    "result = permutation_importance(hgb, test_input, test_target, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "print(result.importances_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b7d24f1d-529e-4e07-931e-71ebd05f9ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8584615384615385"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 세트에서의 성능 확인\n",
    "hgb.score(test_input, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4d9d3a-c1d3-4180-a60e-2eefcf101d3c",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "- 그레이디언트 부스팅 알고리즘을 구현한 라이브러리 중 하나\n",
    "- tree_method 매개변수를 hist로 지정해 히스토그램 기반 그레이디언트 부스팅 사용 가능\n",
    "\n",
    "### LightGBM\n",
    "- 마이크로스프트에서 만든 그레이디언트 부스팅 알고리즘을 구현한 라이브러리 중 하나"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
